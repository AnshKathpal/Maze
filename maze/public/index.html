<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="icon" href="%PUBLIC_URL%/favicon.ico" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#000000" />
    <meta
      name="description"
      content="Web site created using create-react-app"
    />
    <link rel="apple-touch-icon" href="%PUBLIC_URL%/logo192.png" />
    <!--
      manifest.json provides metadata used when your web app is installed on a
      user's mobile device or desktop. See https://developers.google.com/web/fundamentals/web-app-manifest/
    -->
    <link rel="manifest" href="%PUBLIC_URL%/manifest.json" />
    <!--
      Notice the use of %PUBLIC_URL% in the tags above.
      It will be replaced with the URL of the `public` folder during the build.
      Only files inside the `public` folder can be referenced from the HTML.

      Unlike "/favicon.ico" or "favicon.ico", "%PUBLIC_URL%/favicon.ico" will
      work correctly both with client-side routing and a non-root public URL.
      Learn how to configure a non-root public URL by running `npm run build`.
    -->
    <title>React App</title>

    <style>


.buttonStart{

  display: flex;
  justify-content: center;
  align-items: center;

}

button {
  font-size: 20px;
}
    </style>
    
  </head>
  <body>
    <noscript>You need to enable JavaScript to run this app.</noscript>
    <div id="root"></div>
    <!--
      This HTML file is a template.
      If you open it directly in the browser, you will see an empty page.

      You can add webfonts, meta tags, or analytics to this file.
      The build step will place the bundled scripts into the <body> tag.

      To begin the development, run `npm start` or `yarn start`.
      To create a production bundle, use `npm run build` or `yarn build`.
    -->

    
    <div class = "buttonStart" >
      <button type="button"  id="startButton" onclick="init()">Start the Game</button>
    </div>
    <div id="label-container"></div>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>
    
    <script type="text/javascript">
        // more documentation available at
        // https://github.com/tensorflow/tfjs-models/tree/master/speech-commands
    
        // the link to your model provided by Teachable Machine export panel
        const URL = "https://teachablemachine.withgoogle.com/models/sJWTWVwHQ/";
    

        let recognizer;
        let isActive = false;

        async function createModel() {
            const checkpointURL = URL + "model.json"; // model topology
            const metadataURL = URL + "metadata.json"; // model metadata
    
            recognizer = speechCommands.create(
                "BROWSER_FFT", // fourier transform type, not useful to change
                undefined, // speech commands vocabulary feature, not useful for your models
                checkpointURL,
                metadataURL);
    
            // check that model and metadata are loaded via HTTPS requests.
            await recognizer.ensureModelLoaded();
    
            return recognizer;
        }


        function toggleVoiceCommand() {
    const startButton = document.getElementById("startButton");
    const stopButton = document.getElementById("stopButton");

    if (!isActive) {
        init();
        startButton.textContent = "Shut Off Voice Command";
        
    } else {
        recognizer.stopListening();
        startButton.textContent = "Activate Voice Command";
        
    }
    isActive = !isActive;
}
    
        async function init() {
            if (!recognizer) {
            const recognizer = await createModel();
            }
            const classLabels = recognizer.wordLabels(); // get class labels
            const labelContainer = document.getElementById("label-container");
            for (let i = 0; i < classLabels.length; i++) {
                labelContainer.appendChild(document.createElement("div"));
            }
    
            // listen() takes two arguments:
            // 1. A callback function that is invoked anytime a word is recognized.
            // 2. A configuration object with adjustable fields
            recognizer.listen(result => {
                const scores = result.scores; // probability of prediction for each class
                // render the probability scores per class
                const recognizedCommand = classLabels[result.scores.indexOf(Math.max(...result.scores))];

                const event = new CustomEvent('voiceCommandRecognized', { detail: recognizedCommand });
        document.dispatchEvent(event);
                for (let i = 0; i < classLabels.length; i++) {
                    const classPrediction = classLabels[i] + ": " + result.scores[i].toFixed(2);
                    labelContainer.childNodes[i].innerHTML = classPrediction;
                }
            }, {
                includeSpectrogram: true, // in case listen should return result.spectrogram
                probabilityThreshold: 0.75,
                invokeCallbackOnNoiseAndUnknown: true,
                overlapFactor: 0.50 // probably want between 0.5 and 0.75. More info in README
            });

            function stopRecognition() {
    if (recognizer) {
        recognizer.stopListening();
    }

    const startButton = document.getElementById("startButton");
    const stopButton = document.getElementById("stopButton");

    startButton.textContent = "Activate Voice Command";
    // stopButton.style.display = "none";
    isActive = false;
}
    
            // Stop the recognition in 5 seconds.
            // setTimeout(() => recognizer.stopListening(), 5000);
        }
    </script>
    





  </body>
</html>
